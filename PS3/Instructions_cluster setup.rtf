{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;\f2\fnil\fcharset0 HelveticaNeue;
\f3\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red83\green83\blue83;\red246\green244\blue207;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural

\f0\fs24 \cf0 Additional notes on PS3.\
\
1) First create S3 bucket in AWS. (this is like a dropbox folder)\
	Call is whatever you want. \
	Create folders: data, log, bootstrap\
	Copy the bank.csv file into the data folder (refer to problemset pdf)\
	Copy the \'93install-jupyter-notebook-pySpark.sh\'94 file to the bootstrap folder. (Box/resources)\
\
2) Create user. \
	From the home page of AWS go to Security & Identity::Identity & Access Management\
	Pick Users and then Create New Users\
	Save the \
\
3) Attach policies to user\
	In the same section Pick Policies\
	Attach the following policies to your user:\
		IAMFullAccess\
		AmazonElasticMapReduceRole\
		AmazonElasticMapReduceEC2Role\
		AmazonElasticMapReduceFullAccess\
\
4) Run the code in the other text file (EMR cluster setup on AWS) in the command line. \
	In the last command (the long one) make sure you change the following:\
		\'93your_bucket\'94 to the name of your S3 bucket. (there are 2 instances)\
		\'93myKey\'94 to the Access Key Id from step 2. \
		take out all the annoying backslashes that are in the code in the pdf.\
\
5) Go to cluster security groups and edit inbound rules\
		Add SSH, with source as Anywhere\
\
\
My Info:\
\
\pard\pardeftab720

\f1 \cf0 \expnd0\expndtw0\kerning0
IPython\
\
password: python\
\pard\pardeftab720\sa240
\cf0 \expnd0\expndtw0\kerning0
'sha1:7e36c73423d9:36caebea0c06198829388f4f25602c81f63503df\'92\
\uc0\u8232 \
AWS Users & Policies\
User: Anneke\
Access Key ID:\'a0
\f2\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
AKIAJ44DDIPBN3G5BMXQ
\f1\fs24 \cf0 \cb1 \expnd0\expndtw0\kerning0
\

\f2\fs28 \cf2 \cb3 \expnd0\expndtw0\kerning0
Secret Access Key:\'a0/KQVytIAhnAXEJX8VDtub66jvp1PoiOlwHehplx1
\f1\fs24 \cf0 \cb1 \expnd0\expndtw0\kerning0
\
\pard\pardeftab720
\cf0 \expnd0\expndtw0\kerning0
aws\'a0emr create-cluster \'a0--name Spark-Jupyter-Cluster \'a0--ami-version 3.8.0 \'a0--instance-type m3.xlarge \'a0--instance-count 4 \'a0--applications Name=GANGLIA Name=SPARK,Args=[-g,-d,spark.executor.memory=10g] \'a0--bootstrap-actions Path=s3://pysparkhomework/bootstrap/install-jupyter-notebook-pySpark.sh,Name=Install_Jupyter \'a0--region eu-west-1 \'a0--use-default-roles \'a0--ec2-attributes KeyName=annekesfirstkeypair \'a0--enable-debugging \'a0--log-uri s3://pysparkhomework/Log/ \'a0--termination-protected\
\
\pard\pardeftab720

\f3\fs22 \cf0 \expnd0\expndtw0\kerning0
"ClusterId": "j-2SDTHIMXHPDNP\'94\
\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural
\cf0 \kerning1\expnd0\expndtw0 \CocoaLigature0 "MasterPublicDnsName": "ec2-52-49-249-29.eu-west-1.compute.amazonaws.com"\expnd0\expndtw0\kerning0
\CocoaLigature1 \
}